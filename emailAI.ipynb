{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25gAEIQDaZMs"
      },
      "outputs": [],
      "source": [
        "%pip install -q -U google-generativeai nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGSA8IIp1QsN"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.generativeai'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cVYl3bztKXg",
        "outputId": "b7935dbc-96fe-4670-9fad-6fcb978c7d56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup concluído com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Download de recursos para NLP\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "\n",
        "try:\n",
        "    API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=API_KEY)\n",
        "    model = genai.GenerativeModel('gemini-3-flash-preview')\n",
        "    print(\"Setup concluído com sucesso!\")\n",
        "except:\n",
        "    print(\"Configure sua GEMINI_API_KEY nos Secrets do Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emukkpmc3kZd",
        "outputId": "3b4fc85a-3a08-440b-f22d-c606cd3737dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo limpo: olá segue boleto anexo\n"
          ]
        }
      ],
      "source": [
        "def pre_processar_texto(texto):\n",
        "    if not texto: return \"\"\n",
        "\n",
        "    # 1. Padronização para minúsculo\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # 2. Remoção de URLs e caracteres especiais (mantendo acentos)\n",
        "    texto = re.sub(r'http\\S+|www\\S+|https\\S+', '', texto)\n",
        "    texto = re.sub(r'[^a-zA-Záàâãéèêíïóôõöúçñ1-9\\s]', '', texto)\n",
        "\n",
        "    # 3. Remoção de Stop Words\n",
        "    palavras = texto.split()\n",
        "    palavras_filtradas = [w for w in palavras if w not in stop_words]\n",
        "\n",
        "    return \" \".join(palavras_filtradas)\n",
        "\n",
        "# Teste rápido\n",
        "print(f\"Exemplo limpo: {pre_processar_texto('Olá! Segue o boleto em anexo.')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLiNcoAm3n7l"
      },
      "outputs": [],
      "source": [
        "def classificar_email(texto_limpo):\n",
        "    prompt = f\"\"\"\n",
        "    Classifique o email financeiro abaixo em uma destas categorias:\n",
        "    - 'Produtivo': Requisições, dúvidas técnicas, status de boletos ou envio de arquivos.\n",
        "    - 'Improdutivo': Saudações, agradecimentos, mensagens festivas ou spans.\n",
        "\n",
        "    Texto: {texto_limpo}\n",
        "\n",
        "    Retorne APENAS um JSON no formato: {{\"categoria\": \"Produtivo ou Improdutivo\"}}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        # Limpa formatação de markdown se houver\n",
        "        json_text = response.text.replace('```json', '').replace('```', '').strip()\n",
        "        return json.loads(json_text)\n",
        "    except Exception as e:\n",
        "        return {\"erro\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxm1CDOZ3xdA"
      },
      "outputs": [],
      "source": [
        "def sugerir_resposta(texto_limpo, categoria):\n",
        "    if categoria == \"Improdutivo\":\n",
        "        return \"Agradecemos o contato. Desejamos um excelente dia!\"\n",
        "    prompt = f\"\"\"\n",
        "    Você é um assistente de marketing financeiro da empresa AutoU.\n",
        "    Gere uma resposta curta e profissional para um cliente financeiro.\n",
        "    O email dele tratava de: {texto_limpo}\n",
        "    A resposta deve ser empática e informar que o time técnico já está analisando.\n",
        "    Apenas uma opção.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except:\n",
        "        return \"Recebemos sua mensagem e daremos retorno em breve.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "CFxyqtGi3rUv",
        "outputId": "5e6970c5-6425-4026-c99d-41584aeae5cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- RESULTADO DA ANÁLISE ---\n",
            "Categoria: Não Identificado\n",
            "Resposta Sugerida: Olá, [Nome do Cliente].\n",
            "\n",
            "Compreendemos a importância do seu pedido e agradecemos a paciência. Informamos que o seu processo de reembolso já está em análise prioritária pelo nosso time técnico para que tudo seja resolvido o quanto antes.\n",
            "\n",
            "Em breve, entraremos em contato com uma atualização.\n",
            "\n",
            "Atenciosamente,\n",
            "**Equipe AutoU**\n"
          ]
        }
      ],
      "source": [
        "# Simulando a entrada de um email\n",
        "email_entrada = \"Bom dia time! Gostaria de uma atualização sobre o meu processo de reembolso.\"\n",
        "\n",
        "# 1. Limpeza\n",
        "texto_limpo = pre_processar_texto(email_entrada)\n",
        "\n",
        "# 2. Classificação\n",
        "classificacao_dict = classificar_email(texto_limpo)\n",
        "categoria = classificacao_dict.get(\"categoria\", \"Não Identificado\")\n",
        "\n",
        "# 3. Resposta\n",
        "resposta = sugerir_resposta(texto_limpo, categoria)\n",
        "\n",
        "# Resultado Final\n",
        "print(f\"--- RESULTADO DA ANÁLISE ---\")\n",
        "print(f\"Categoria: {categoria}\")\n",
        "print(f\"Resposta Sugerida: {resposta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAvfpcLq5qqQ"
      },
      "outputs": [],
      "source": [
        "%pip install PyPDF2 -q\n",
        "import PyPDF2\n",
        "import io\n",
        "\n",
        "def extrair_texto_arquivo(file_bytes, filename):\n",
        "    \"\"\"Extrai texto de arquivos PDF ou TXT enviados pelo usuário.\"\"\"\n",
        "    if filename.endswith('.pdf'):\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_bytes))\n",
        "            texto = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                texto += page.extract_text() or \"\"\n",
        "            return texto\n",
        "        except Exception as e:\n",
        "            return f\"Erro ao ler PDF: {e}\"\n",
        "    elif filename.endswith('.txt'):\n",
        "        return file_bytes.decode(\"utf-8\")\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf1ppzeF50rv"
      },
      "outputs": [],
      "source": [
        "%pip install fastapi uvicorn python-multipart nest-asyncio pyngrok -q\n",
        "from fastapi import FastAPI, UploadFile, File, Form\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "import nest_asyncio\n",
        "import time\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Configuração de CORS para permitir que seu site acesse o backend\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "@app.post(\"/analisar\")\n",
        "async def api_analisar_email(\n",
        "    texto: str = Form(None),\n",
        "    arquivo: UploadFile = File(None)\n",
        "):\n",
        "    # 1. Captura o conteúdo bruto (seja texto direto ou de arquivo)\n",
        "    email_bruto = \"\"\n",
        "    if arquivo:\n",
        "        file_bytes = await arquivo.read()\n",
        "        email_bruto = extrair_texto_arquivo(file_bytes, arquivo.filename)\n",
        "    else:\n",
        "        email_bruto = texto\n",
        "\n",
        "    if not email_bruto:\n",
        "        return {\"erro\": \"Nenhum conteúdo recebido.\"}\n",
        "\n",
        "    # 2. Orquestração das funções que você já criou\n",
        "    texto_limpo = pre_processar_texto(email_bruto)\n",
        "    resultado_classe = classificar_email(texto_limpo)\n",
        "    categoria = resultado_classe.get(\"categoria\", \"Não Identificado\")\n",
        "    resposta = sugerir_resposta(texto_limpo, categoria)\n",
        "\n",
        "    return {\n",
        "        \"categoria\": categoria,\n",
        "        \"resposta_sugerida\": resposta\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ONpcdNbC6Tyk",
        "outputId": "251be739-418a-49ec-e03e-227c93c84cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EMAIL ORIGINAL                                     | CATEGORIA       | RESPOSTA OK?\n",
            "-------------------------------------------------------------------------------------\n",
            "Olá, segue em anexo o comprovante do boleto pago  ... | Produtivo       | ✅\n",
            "Bom dia! Gostaria de saber por que minha taxa de  ... | Erro            | ✅\n",
            "Feliz Natal para toda a equipe da AutoU! Vocês s  ... | Improdutivo     | ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-3-flash-preview:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 2718.91ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obrigado pelo retorno, tenha um bom dia!          ... | Improdutivo     | ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-3-flash-preview:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 554.44ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PRECISO DE AJUDA! Meu sistema travou e não consi  ... | Erro            | ✅\n"
          ]
        }
      ],
      "source": [
        "# Célula de Teste de Qualidade\n",
        "emails_para_teste = [\n",
        "    \"Olá, segue em anexo o comprovante do boleto pago ontem. Favor confirmar o recebimento.\", # Esperado: Produtivo\n",
        "    \"Bom dia! Gostaria de saber por que minha taxa de manutenção aumentou este mês.\", # Esperado: Produtivo\n",
        "    \"Feliz Natal para toda a equipe da AutoU! Vocês são nota 10.\", # Esperado: Improdutivo\n",
        "    \"Obrigado pelo retorno, tenha um bom dia!\", # Esperado: Improdutivo\n",
        "    \"PRECISO DE AJUDA! Meu sistema travou e não consigo emitir a nota fiscal agora.\" # Esperado: Produtivo\n",
        "]\n",
        "\n",
        "print(f\"{'EMAIL ORIGINAL':<50} | {'CATEGORIA':<15} | {'RESPOSTA OK?'}\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "for email in emails_para_teste:\n",
        "    time.sleep(4)\n",
        "    limpo = pre_processar_texto(email)\n",
        "    classe = classificar_email(limpo)\n",
        "    cat = classe.get(\"categoria\", \"Erro\")\n",
        "    resp = sugerir_resposta(limpo, cat)\n",
        "\n",
        "    # Verifica se a resposta contém palavras profissionais esperadas\n",
        "    valido = \"✅\" if len(resp) > 10 else \"❌\"\n",
        "    print(f\"{email[:48]:<50}... | {cat:<15} | {valido}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.9.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
